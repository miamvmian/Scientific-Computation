{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RCCU6dck3AxL"
      },
      "source": [
        "## Python\n",
        "\n",
        "* Great for prototyping, scripting, has a lot of useful libraries\n",
        "* Not suitable for low-level programming, but OK if the computation can be vectorized (Numpy)\n",
        "* Great for visualizing results (Matplotlib)\n",
        "\n",
        "## Jupyter notebooks (https://jupyter.org/)\n",
        "\n",
        "* Great for presenting Python workflows\n",
        "* Many useful features (Latex, interactive widgets, etc.)\n",
        "\n",
        "## Google colab (https://colab.research.google.com)\n",
        "\n",
        "* Great for sharing Python notebooks\n",
        "* No need for a local Python distribution\n",
        "* GPUs available"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YqqptyAs3AxT"
      },
      "source": [
        "## Numpy for common vector/matrix operations\n",
        "Avoid Python loops; use Numpy functions instead.\n",
        "\n",
        "### Example: compare several methods to sum an array\n",
        "Standard imports:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8eAyIEIg3Axa"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import time"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FJ6sTaEA3AyD"
      },
      "source": [
        "Generate a random N x N array:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1RhTjnOb3AyK"
      },
      "outputs": [],
      "source": [
        "N = 3000\n",
        "A = np.random.normal(size=(N,N)) # an NxN array with random, normally distributed values\n",
        "assert A.shape[0] == N and A.shape[1] == N"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P4TvpSAO3Ayf"
      },
      "source": [
        "Consider several methods of suming the array:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I6RXB2ub3Ayj"
      },
      "outputs": [],
      "source": [
        "# Method 1 - Python loop\n",
        "t0 = time.time()\n",
        "sum1 = 0\n",
        "for n0 in range(N):\n",
        "    for n1 in range(N):\n",
        "        sum1 += A[n0, n1]\n",
        "dt1 = time.time()-t0\n",
        "print ('Sum:', sum1)\n",
        "print ('Time of Python loop:', dt1)\n",
        "\n",
        "# Method 2 - Numpy's sum\n",
        "t0 = time.time()\n",
        "sum2 = np.sum(A)\n",
        "dt2 = time.time()-t0\n",
        "assert np.abs(sum1-sum2) < 1e-8\n",
        "print ('Time of Numpy sum  :', dt2)\n",
        "\n",
        "# Method 3 - sum rows, then resulting column\n",
        "t0 = time.time()\n",
        "sum3 = 0\n",
        "for n0 in range(N):\n",
        "    sum3 += np.sum(A[n0,:])\n",
        "dt3 = time.time()-t0\n",
        "assert np.abs(sum1-sum3) < 1e-8\n",
        "print ('Time of Method 3   :', dt3)\n",
        "\n",
        "# Method 4 - sum columns, then resulting row\n",
        "t0 = time.time()\n",
        "sum4 = 0\n",
        "for n1 in range(N):\n",
        "    sum4 += np.sum(A[:,n1])\n",
        "dt4 = time.time()-t0\n",
        "assert np.abs(sum1-sum4) < 1e-8\n",
        "print ('Time of Method 4   :', dt4)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yJFw7nGV3Ay5"
      },
      "source": [
        "**Exercise:** why is Method 4 slower than Method 3?\n",
        "\n",
        "## Cython: accelerating Python code\n",
        "\n",
        "Some useful tutorials:\n",
        "* https://cython.readthedocs.io/en/latest/src/quickstart/index.html\n",
        "* https://cython.readthedocs.io/en/latest/src/userguide/numpy_tutorial.html#numpy-tutorial"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zXRhtxnJ3Ay_"
      },
      "outputs": [],
      "source": [
        "%load_ext cython"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s6kfj_wz3AzS"
      },
      "source": [
        "Write and compile a Cython function for the sum:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6bJBnqh-3AzZ"
      },
      "outputs": [],
      "source": [
        "%%cython -a\n",
        "# use \"%%cython -a\" to see color highlights of slower parts\n",
        "cimport numpy as np\n",
        "\n",
        "cpdef sum_cython(np.ndarray[double, ndim=2] A):\n",
        "    cdef double sum0 = 0\n",
        "    cdef int n0, n1, N\n",
        "    N = A.shape[0]\n",
        "    for n0 in range(N):\n",
        "        for n1 in range(N):\n",
        "            sum0 = sum0 + A[n0,n1]\n",
        "    return sum0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BRjd7aab3Azw"
      },
      "source": [
        "Test evaluation time:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WB0qqEmH3Azy"
      },
      "outputs": [],
      "source": [
        "t0 = time.time()\n",
        "sum5 = sum_cython(A)\n",
        "dt5 = time.time()-t0\n",
        "assert np.abs(sum1-sum5) < 1e-8\n",
        "print ('Time of Cython:', dt5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bq8UtRHx3A0F"
      },
      "source": [
        "To have inline plots (instead of 'inline' one can in principle use different backends like nbagg, qt, wx or auto)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6oY8cfCo3A0H"
      },
      "outputs": [],
      "source": [
        "# render plots in the notebook\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mNYZSg_j3A0X"
      },
      "source": [
        "## Example: curve fitting by least squares\n",
        "Let $f(t)=a_0+a_1t+\\xi_t$, where $\\xi_t\\sim\\mathcal N(0,\\epsilon)$ is a Gaussian white noise.  \n",
        "\n",
        "#### 1. Creating the data to be fitted"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Sej_bpat3A0a"
      },
      "outputs": [],
      "source": [
        "a0 = np.random.normal()\n",
        "a1 = np.random.normal()\n",
        "print ('a0 = %f, a1 = %f' %(a0, a1))\n",
        "N = 10 # number of observations\n",
        "x = np.arange(0,N)\n",
        "epsilon = 1e-1\n",
        "xi = np.sqrt(epsilon)*np.random.normal(size=(N,))\n",
        "y = a0+a1*x\n",
        "y_noisy = y+xi\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(y, '-x', label='original linear model')\n",
        "plt.plot(y_noisy, 'o', label='noisy observations')\n",
        "plt.legend(loc='best')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vPRa9oqN3A0r"
      },
      "source": [
        "#### 2. Fitting the model to the data\n",
        "Let us fit a straight line to the observations by least squares:\n",
        "$$\\|F{\\mathbf a}-\\mathbf{y}\\|^2\\to\\min_{\\mathbf a},$$\n",
        "where\n",
        "$$F =\n",
        "\\begin{pmatrix}\n",
        "1 & t_1\\\\\n",
        "\\vdots & \\vdots \\\\\n",
        "1 & t_N\n",
        "\\end{pmatrix},\n",
        "\\mathbf a =\n",
        "\\begin{pmatrix}\n",
        "a_0\\\\\n",
        "a_1\n",
        "\\end{pmatrix},\n",
        "\\mathbf y =\n",
        "\\begin{pmatrix}\n",
        "y_1\\\\\n",
        "\\vdots \\\\\n",
        "y_N\n",
        "\\end{pmatrix},\n",
        "\\|\\mathbf v\\|^2=\\sum_n v_n^2. $$\n",
        "\n",
        "Many ways to solve this problem with Python:\n",
        "\n",
        "**Approach 1:** Exact solution $\\mathbf a = (F^tF)^{-1}F^t\\mathbf y.$\n",
        "\n",
        "**Approach 2:** Numerical optimization by a general purpose optimization algorithm from `scipy`.\n",
        "\n",
        "**Approach 3:** Numpy library function for least squares.\n",
        "\n",
        "**Approach 4:** Direct numerical gradient descent optimization using `pytorch`.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v2bETgmi3A0u"
      },
      "outputs": [],
      "source": [
        "F = np.ones((len(x),2))\n",
        "F[:,1] = x\n",
        "\n",
        "def myopt(F, y_noisy, approach):\n",
        "    if approach == 1:\n",
        "        aa = np.dot(np.dot(np.linalg.inv(np.dot(F.T, F)), F.T), y_noisy)\n",
        "\n",
        "    elif approach == 2:\n",
        "        import scipy.optimize\n",
        "        def f(aa):\n",
        "            diff = np.dot(F, aa)-y_noisy\n",
        "            return np.sum(diff*diff)\n",
        "        res = scipy.optimize.minimize(f, x0=[0,0])\n",
        "        aa = res['x']\n",
        "\n",
        "    elif approach == 3:\n",
        "        aa = np.linalg.lstsq(F, y_noisy, rcond=None)[0]\n",
        "\n",
        "    elif approach == 4:\n",
        "        import torch\n",
        "\n",
        "        aa_t = torch.tensor([0.,0.], dtype=torch.double, requires_grad=True)\n",
        "        F_t = torch.tensor(F)\n",
        "        y_noisy_t = torch.tensor(y_noisy)\n",
        "\n",
        "        def getloss():\n",
        "            diff = torch.einsum('ab,b->a', F_t, aa_t)-y_noisy_t\n",
        "            loss = (diff**2).sum()\n",
        "            return loss\n",
        "\n",
        "        learning_rate = 1e-3\n",
        "        for k in range(1000):\n",
        "            loss = getloss()\n",
        "            loss.backward()\n",
        "            aa_t.data -= learning_rate*aa_t.grad.data\n",
        "            aa_t.grad.zero_()\n",
        "        aa = aa_t.detach().numpy()\n",
        "\n",
        "    return aa\n",
        "\n",
        "\n",
        "for approach in range(1, 5):\n",
        "    aa = myopt(F, y_noisy, approach)\n",
        "    print ('Approach %d: a0 = %f, a1 = %f' %(approach, aa[0], aa[1]))\n",
        "\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(y, '-', label='original linear model')\n",
        "plt.plot(y_noisy, 'o', label='noisy observations')\n",
        "plt.plot(np.dot(F, aa), '-', label='fitted linear model')\n",
        "plt.legend(loc='best')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-jjda9lq3A0_"
      },
      "source": [
        "### Pytorch\n",
        "\n",
        "* Analytic differentiation for any computational graph\n",
        "* Great for gradient based optimization of complex functions\n",
        "* In contrast to NumPy, works on GPU\n",
        "\n",
        "**Exercise:** Perform curve fitting with a 2nd degree polynomial.\n",
        "\n",
        "**Exercise:** What is the limiting (large-$N$) shape of the histogram below?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6zPyIWLK3A1C"
      },
      "outputs": [],
      "source": [
        "N = 2000\n",
        "A = np.random.normal(size=(N, N))\n",
        "B = A+A.T\n",
        "eigenvalues = np.linalg.eigh(B)[0]\n",
        "\n",
        "plt.figure()\n",
        "plt.hist(eigenvalues, bins=100)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ux54cRVN3A1X"
      },
      "source": [
        "## Matplotlib animation\n",
        "\n",
        "A useful tutorial: https://jakevdp.github.io/blog/2012/08/18/matplotlib-animation-tutorial/\n",
        "\n",
        "(Possibly disable inline plotting by %matplotlib auto; play with backends or restart the kernel if animation doesn't play.)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iiQ4LJUe3A1f",
        "scrolled": false
      },
      "outputs": [],
      "source": [
        "%matplotlib auto\n",
        "\n",
        "# for colab\n",
        "from matplotlib import animation, rc\n",
        "rc('animation', html='jshtml')\n",
        "\n",
        "\"\"\"\n",
        "Matplotlib Animation Example\n",
        "\n",
        "author: Jake Vanderplas\n",
        "email: vanderplas@astro.washington.edu\n",
        "website: http://jakevdp.github.com\n",
        "license: BSD\n",
        "Please feel free to use and modify this, but keep the above information. Thanks!\n",
        "\"\"\"\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.animation as animation\n",
        "\n",
        "# First set up the figure, the axis, and the plot element we want to animate\n",
        "fig = plt.figure()\n",
        "ax = plt.axes(xlim=(0, 2), ylim=(-2, 2))\n",
        "line, = ax.plot([], [], lw=2)\n",
        "\n",
        "# initialization function: plot the background of each frame\n",
        "def init():\n",
        "    line.set_data([], [])\n",
        "    return line,\n",
        "\n",
        "# animation function.  This is called sequentially\n",
        "def animate(i):\n",
        "    x = np.linspace(0, 2, 1000)\n",
        "    y = np.sin(2 * np.pi * (x - 0.01 * i))\n",
        "    line.set_data(x, y)\n",
        "    return line,\n",
        "\n",
        "# call the animator.  blit=True means only re-draw the parts that have changed.\n",
        "anim = animation.FuncAnimation(fig, animate, init_func=init,\n",
        "                               frames=200, interval=20, blit=True)\n",
        "\n",
        "# save the animation as an mp4.  This requires ffmpeg or mencoder to be\n",
        "# installed.  The extra_args ensure that the x264 codec is used, so that\n",
        "# the video can be embedded in html5.  You may need to adjust this for\n",
        "# your system: for more information, see\n",
        "# http://matplotlib.sourceforge.net/api/animation_api.html\n",
        "# anim.save('basic_animation.mp4', fps=30, extra_args=['-vcodec', 'libx264'])\n",
        "\n",
        "# for local notebook\n",
        "# plt.show()\n",
        "\n",
        "# for colab\n",
        "plt.close()\n",
        "anim"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "inAuH58e3A13"
      },
      "source": [
        "### Particles in a box under Lennard-Jones potential"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wQygfKWM3A16"
      },
      "outputs": [],
      "source": [
        "def LJ(r, eps=1., sigma=1.):\n",
        "    sr = sigma/r\n",
        "    return 4*eps*(sr**12-sr**6)\n",
        "\n",
        "N = 100 # number of particles\n",
        "L = 5. # size of the box\n",
        "v0std = 1. # initial velocity std per axis per particle\n",
        "\n",
        "init_pos = 'regular'\n",
        "if init_pos == 'regular':\n",
        "    cellsPerSide = int(np.ceil(N**(1./3)))\n",
        "    L1 = L/cellsPerSide\n",
        "    x0 = np.zeros((N,3))\n",
        "    x0[:,0] = np.arange(N)%cellsPerSide\n",
        "    a = np.arange(N)//cellsPerSide\n",
        "    x0[:,1] = a%cellsPerSide\n",
        "    x0[:,2] = a//cellsPerSide\n",
        "    x0 = L1/2+L1*x0\n",
        "\n",
        "elif init_pos == 'random':\n",
        "    x0 = L*np.random.rand(N,3)\n",
        "else:\n",
        "    raise NotImplementedError\n",
        "\n",
        "\n",
        "v0 = v0std*np.random.normal(size=(N,3))\n",
        "\n",
        "def F_all(x, eps=1., sigma=1.):\n",
        "    x1 = np.broadcast_to(x.reshape((N,1,3)), (N,N,3))\n",
        "    x2 = np.broadcast_to(x.reshape((1,N,3)), (N,N,3))\n",
        "    R = x2-x1\n",
        "    R = (R+L/2.)%L-L/2. # periodic b.c.\n",
        "    assert np.all(R >= -L/2.) and np.all(R <= L/2.)\n",
        "    r = np.sqrt(np.sum(R*R, axis=2))+1e-10\n",
        "    sr = sigma/r\n",
        "    F0 = 4*eps*(12*sr**12/r-6*sr**6/r) # scalar values of forces\n",
        "    F = R*np.broadcast_to((F0/r).reshape((N,N,1)), (N,N,3))\n",
        "    F[range(N), range(N)] = 0 # exclude self-action\n",
        "    assert np.sum(np.isnan(F)) == 0\n",
        "    return -np.sum(F, axis=1)\n",
        "\n",
        "def integrate(F_all, x, v, dt, N):\n",
        "    xHistory = [x0]\n",
        "    vHistory_ = [v0+dt/2.*F_all(x)]\n",
        "    for n in range(N):\n",
        "        xHistory.append(np.remainder(xHistory[-1]+dt*vHistory_[-1], L))\n",
        "        vHistory_.append(1.*(vHistory_[-1]+dt*F_all(xHistory[-1])))\n",
        "    vHistory = [(vHistory_[n]+vHistory_[n+1])/2. for n in range(len(vHistory_)-1)]\n",
        "    assert len(xHistory) == len(vHistory)+1\n",
        "    return xHistory[1:], vHistory\n",
        "\n",
        "m = 2\n",
        "dt = 10**(-m)\n",
        "t0 = time.time()\n",
        "xHistory, vHistory = integrate(F_all, x0, v0, dt=dt, N=int(3./dt))\n",
        "print ('Simulation time:', time.time()-t0)\n",
        "\n",
        "tHistory = dt*np.arange(len(xHistory))\n",
        "\n",
        "import mpl_toolkits.mplot3d.axes3d as p3\n",
        "from matplotlib.patches import Rectangle, PathPatch\n",
        "import mpl_toolkits.mplot3d.art3d as art3d\n",
        "\n",
        "fig = plt.figure(figsize=(8,8))\n",
        "ax = plt.axes(projection = '3d')\n",
        "\n",
        "dots, = plt.plot(xHistory[0][:,0], xHistory[0][:,1], xHistory[0][:,2], 'ob')\n",
        "print(dots)\n",
        "\n",
        "plt.axis('off')\n",
        "\n",
        "ax.set_xlim3d([0, L])\n",
        "ax.set_ylim3d([0, L])\n",
        "ax.set_zlim3d([0, L])\n",
        "\n",
        "title = plt.title('')\n",
        "\n",
        "for zdir in ['x','y','z']:\n",
        "    for z in [0,L]:\n",
        "        p = Rectangle((0,0), L, L, color='r', alpha=0.1)\n",
        "        ax.add_patch(p)\n",
        "        art3d.pathpatch_2d_to_3d(p, z=z, zdir=zdir)\n",
        "\n",
        "skip = 1\n",
        "\n",
        "def animate(i):\n",
        "    dots.set_data(xHistory[::skip][i][:,0], xHistory[::skip][i][:,1])\n",
        "    dots.set_3d_properties(xHistory[::skip][i][:,2])\n",
        "    title.set_text(\"t = %2.3f\" %(tHistory[::skip][i]))\n",
        "\n",
        "\n",
        "anim = animation.FuncAnimation(fig, animate, len(tHistory[::skip]),\n",
        "    interval=1)\n",
        "\n",
        "# for local notebook\n",
        "# plt.show()\n",
        "\n",
        "# for colab\n",
        "plt.close()\n",
        "anim"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zn_5KZHIiSQ9"
      },
      "source": [
        "### The heat equation with torch; use CPU or GPU"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-IuftpiFkvst"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import time\n",
        "import matplotlib.pyplot as plt\n",
        "# for colab\n",
        "from matplotlib import animation, rc\n",
        "rc('animation', html='jshtml')\n",
        "\n",
        "# Get cpu or gpu device for training.\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "#device = \"cpu\"\n",
        "print(\"Using {} device\".format(device))\n",
        "\n",
        "N = 300\n",
        "dx = 1./N\n",
        "x0, x1 = torch.meshgrid(dx*torch.arange(N).to(device),\n",
        "                        dx*torch.arange(N).to(device))\n",
        "u0 = torch.exp(-70*(4*(x0-0.3)**2+(x1-0.6)**2))+0.5*torch.exp(-20*((x0-0.6)**2+(x1-0.4)**2))\n",
        "dt = 5e-6\n",
        "a = 1.\n",
        "uHistory = []\n",
        "skip = 30\n",
        "u = 1*u0\n",
        "\n",
        "t0 = time.time()\n",
        "for n in range(3000):\n",
        "    if n%skip == 0:\n",
        "        uHistory.append(1*u)\n",
        "\n",
        "    dudx = torch.zeros_like(u)\n",
        "    dudx[:-1] = u[1:]-u[:-1]\n",
        "    dudx[-1] = u[0]-u[-1]\n",
        "    d2udx2 = torch.zeros_like(u)\n",
        "    d2udx2[1:] = dudx[1:]-dudx[:-1]\n",
        "    d2udx2[0] = dudx[0]-dudx[-1]\n",
        "\n",
        "    dudy = torch.zeros_like(u)\n",
        "    dudy[:,:-1] = u[:,1:]-u[:,:-1]\n",
        "    dudy[:,-1] = u[:,0]-u[:,-1]\n",
        "    d2udy2 = torch.zeros_like(u)\n",
        "    d2udy2[:,1:] = dudy[:,1:]-dudy[:,:-1]\n",
        "    d2udy2[:,0] = dudy[:,0]-dudy[:,-1]\n",
        "\n",
        "    u += a/2.*dt*(1./dx)**2*(d2udx2+d2udy2)\n",
        "\n",
        "print ('Simulation time:', time.time()-t0)\n",
        "\n",
        "tHistory = dt*skip*np.arange(len(uHistory))\n",
        "\n",
        "fig = plt.figure()\n",
        "im = plt.imshow(u.cpu(), vmin=0, vmax=1\n",
        "                , animated=True)\n",
        "plt.colorbar()\n",
        "title = plt.title('')\n",
        "\n",
        "def animate(i):\n",
        "    im.set_array(uHistory[i].cpu().numpy())\n",
        "    title.set_text(\"t = %2.5f\" %(tHistory[i]))\n",
        "\n",
        "anim = animation.FuncAnimation(fig, animate, len(uHistory))\n",
        "\n",
        "# for local notebook\n",
        "# plt.show()\n",
        "\n",
        "# for colab\n",
        "plt.close()\n",
        "anim"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bs3Kek4i3A2b"
      },
      "source": [
        "### Monte-Carlo simulation of the Ising model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oeqWyuBf3A2c"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "# for colab\n",
        "from matplotlib import animation, rc\n",
        "rc('animation', html='jshtml')\n",
        "\n",
        "L = 100\n",
        "N = 2**19\n",
        "beta = 1.\n",
        "J = 1. #0.44\n",
        "h = 0\n",
        "\n",
        "sigma = 2*np.random.randint(0,2,(L,L))-1\n",
        "\n",
        "sigmaHistory = []\n",
        "tHistory_ = [int(500*n*(1+2**(n/400.))) for n in range(200)]\n",
        "nHistory = []\n",
        "\n",
        "for n in range(N-1):\n",
        "    k0, k1 = np.random.randint(L), np.random.randint(L)\n",
        "    # dH = H_new-H_old\n",
        "    dH = 2*sigma[k0,k1]*(J*(sigma[k0,(k1-1)%L]+sigma[k0,(k1+1)%L]+sigma[(k0-1)%L,k1]+sigma[(k0+1)%L,k1])+h)\n",
        "    if dH > 0:\n",
        "        a = np.random.rand()\n",
        "        if a > np.exp(-beta*dH):\n",
        "            continue\n",
        "    sigma[k0,k1] *= -1\n",
        "    if n in tHistory_:\n",
        "        nHistory.append(n)\n",
        "        sigmaHistory.append(sigma.copy())\n",
        "\n",
        "fig = plt.figure()\n",
        "im = plt.imshow(sigma+1, vmin=0, vmax=1, #cmap='Greys_r'\n",
        "                interpolation='none', animated=True)\n",
        "title = plt.title('')\n",
        "\n",
        "def animate(i):\n",
        "    im.set_array(sigmaHistory[i])\n",
        "    title.set_text('Iteration %d' %(nHistory[i]))\n",
        "\n",
        "anim = animation.FuncAnimation(fig, animate, len(sigmaHistory))\n",
        "# for local notebook\n",
        "# plt.show()\n",
        "\n",
        "# for colab\n",
        "plt.close()\n",
        "anim"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.5.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}