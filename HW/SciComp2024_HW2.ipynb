{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5XDBefNIgZE7"
      },
      "source": [
        "## Scientific Computing 2023: Homework Assignment 2\n",
        "Due Sunday October 20, 2023 (23:59)\n",
        "\n",
        "### Problem 1 (2 points)\n",
        "Let $A_q=\\left(\\begin{matrix}1 & q\\\\ 0 & 1\\end{matrix}\\right)$ with $q\\in\\mathbb R$.\n",
        "* For any $q$, find condition number $\\kappa(A_q)$ with respect to the $l^2$-norm.\n",
        "* Give an example of specific values of $q,\\mathbf b, \\Delta\\mathbf b$ such that, when solving $A_q\\mathbf x = \\mathbf b$ and $A_q(\\mathbf x+\\Delta \\mathbf x)=\\mathbf b +\\Delta\\mathbf b$, we get\n",
        "\n",
        "$$\\frac{\\|\\Delta \\mathbf x\\|}{\\|\\mathbf x\\|}\\ge 10^6\\frac{\\|\\Delta\\mathbf b\\|}{\\|\\mathbf b\\|}.$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6jKRLB72gZFE"
      },
      "source": [
        "### Problem 2 (2 points)\n",
        "* Write a program to compute an approximate value for the derivative of a function using the finite-difference formula\n",
        "\n",
        "  $$f'(x)\\approx \\frac{f(x+h)-f(x)}{h}.$$\n",
        "\n",
        "  Test your program using the function $\\tan(x)$ at $x=1$. Determine the error by comparing with the value obtained using the analytic derivative. Plot the magnitude of the error as a function of $h$, for $h=10^{-k}, k=0,\\ldots,16$. You should use log scale for $h$ and for the magnitude of the error. What is the minimum value of the error and at which $h$ is it achieved? Explain this result theoretically.\n",
        "* Repeat the exercise using the centered difference approximation\n",
        "\n",
        " $$f'(x)\\approx \\frac{f(x+h)-f(x-h)}{2h}.$$\n",
        "\n",
        " What is now different and why?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OlohFH9bgZFG"
      },
      "source": [
        "### Problem 3 (2 points)\n",
        "* Implement regularized regression with an adaptive choice of regularization parameter. Your algorithm must accept the training data (`Xtrain`, `Ytrain`) and the input part of test data (`Xtest`), and output a prediction for test data (`Ypred`). You may use standard linear algebra libraries, but not specialized predictive modeling software (e.g., `scikit-learn`). Your algorithm should choose the regularization parameter by some optimization over a reasonable range of values and may use a sub-division of the training data into a train-in-train and a test-in-train components.\n",
        "* Test your algorithm on real data from UCI repository:\n",
        "  * https://archive.ics.uci.edu/ml/datasets/Relative+location+of+CT+slices+on+axial+axis\n",
        "  * https://archive.ics.uci.edu/ml/datasets/Physicochemical+Properties+of+Protein+Tertiary+Structure\n",
        "  \n",
        "  Use random subsets of 300 rows as training sets, and the remaining rows as the test sets. Use the relative RMS error as the measure of accuracy.\n",
        "  Compare your results with results of some linear models implemented in standard predictive modeling software    (e.g., `Ridge` and `LinearRegression` from `scikit-learn`)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3l6EgKSAgZFI"
      },
      "source": [
        "### Problem 4 (2 points)\n",
        "Suppose that we use the Leapfrog algorithm with some $\\Delta t$ to simulate the dynamics of the harmonic oscillator (https://en.wikipedia.org/wiki/Harmonic_oscillator) with positive mass $m$ and force constant $k$ (in other words, with the energy function $H=\\frac{m\\dot x^2}{2}+\\frac{kx^2}{2}$). Assuming a perfect implementation of Leapfrog, at which combinations of $\\Delta t, m, k$ will the simulation diverge as $n\\to\\infty$, in the sense that $\\sup_n(\\tilde x_n^2+\\tilde v_{n+1/2}^2)=\\infty$?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0JlnITqYgZFJ"
      },
      "source": [
        "### Problem 5 (2 points)\n",
        "Suppose that we are solving the ODE $\\frac{d}{dt}\\mathbf {x}=f(\\mathbf x)$ (with, generally, a vector-valued $\\mathbf x(t)$) by iterations\n",
        "\n",
        "$$\\left\\{\\begin{align}\\mathbf k &= f(\\tilde{\\mathbf x}_{n})\\Delta t\\\\\n",
        "\\tilde {\\mathbf x}_{n+1} &= \\tilde {\\mathbf x}_{n}+f(\\tilde{\\mathbf x}_{n}+\\tfrac{1}{2}\\mathbf k)\\Delta t\n",
        "\\end{align}\\right.$$\n",
        "\n",
        "Find the global convergence order of this method, and verify it experimentally."
      ]
    }
  ]
}